set_mode("classification") %>%
set_engine("glmnet")
randomForest_model <- rand_forest(trees = tune(), min_n = tune()) %>%
set_mode("classification") %>%
set_engine("ranger")
XGBoost_model <- boost_tree(tree_depth = tune(), trees = tune()) %>%
set_mode("classification") %>%
set_engine("xgboost")
logistic_wf <- workflow() %>%
add_recipe(tidy_rec) %>%
add_model(logistic_model) %>%
fit(train_data)
# Create models
logistic_model <- logistic_reg(penalty = tune(), mixture = tune()) %>%
set_mode("classification") %>%
set_engine("glm")
randomForest_model <- rand_forest(trees = tune(), min_n = tune()) %>%
set_mode("classification") %>%
set_engine("ranger")
XGBoost_model <- boost_tree(tree_depth = tune(), trees = tune()) %>%
set_mode("classification") %>%
set_engine("xgboost")
logistic_wf <- workflow() %>%
add_recipe(tidy_rec) %>%
add_model(logistic_model) %>%
fit(train_data)
logistic_wf
library(tidymodels)
library(tidyverse)
df <- read_csv("customer_churn.csv")
df %>% summary()
df <- df %>% drop_na()
# Clean data
df <- df %>%
mutate_all(as.factor) %>%
mutate(tenure = as.numeric(tenure),
MonthlyCharges = as.numeric(MonthlyCharges),
TotalCharges = as.numeric(TotalCharges)) %>%
select(Churn, everything(), -customerID)
# Create train and test sets
set.seed(42)
tidy_split <- initial_split(df, prop = .8, strata = Churn)
train_data <- training(tidy_split)
test_data <- testing(tidy_split)
tidy_k_folds <- vfold_cv(train_data)
# Pre-process data
tidy_rec <- recipe(Churn~., data = train_data) %>%
step_normalize(all_numeric()) %>%
step_dummy(all_nominal(), -all_outcomes())
tidy_rec %>% prep()
# Create models
logistic_model <- logistic_reg(penalty = tune(), mixture = tune()) %>%
set_mode("classification") %>%
set_engine("glm")
randomForest_model <- rand_forest(trees = tune(), min_n = tune()) %>%
set_mode("classification") %>%
set_engine("ranger")
XGBoost_model <- boost_tree(tree_depth = tune(), trees = tune()) %>%
set_mode("classification") %>%
set_engine("xgboost")
logistic_res <- fit_resamples(logistic_model, tidy_rec, tidy_k_folds)
logistic_res
randomForest_res <- fit_resamples(randomForest_model, tidy_rec, tidy_k_folds)
# Create models
logistic_model <- logistic_reg(penalty = tune(), mixture = tune()) %>%
set_mode("classification") %>%
set_engine("glm")
randomForest_model <- rand_forest(trees = tune(), min_n = tune()) %>%
set_mode("classification") %>%
set_engine("randomForest")
XGBoost_model <- boost_tree(tree_depth = tune(), trees = tune()) %>%
set_mode("classification") %>%
set_engine("xgboost")
randomForest_res <- fit_resamples(randomForest_model, tidy_rec, tidy_k_folds)
randomForest_res
randomForest_res %>%
pull(.notes) %>%
tidy()
randomForest_res %>%
pull(.notes) %>%
unlist()
randomForest_res %>%
pull(.notes) %>%
unlist() %>%
tidy()
# Create models
logistic_model <- logistic_reg(penalty = tune(), mixture = tune()) %>%
set_mode("classification") %>%
set_engine("glm")
randomForest_model <- rand_forest(mtry = tune(), min_n = tune()) %>%
set_mode("classification") %>%
set_engine("randomForest")
XGBoost_model <- boost_tree(tree_depth = tune(), trees = tune()) %>%
set_mode("classification") %>%
set_engine("xgboost")
randomForest_res <- fit_resamples(randomForest_model, tidy_rec, tidy_k_folds)
XGBoost_res <- fit_resamples(XGBoost_model, tidy_rec, tidy_k_folds)
# Create models
logistic_model <- logistic_reg() %>%
set_mode("classification") %>%
set_engine("glm")
randomForest_model <- rand_forest() %>%
set_mode("classification") %>%
set_engine("randomForest")
XGBoost_model <- boost_tree() %>%
set_mode("classification") %>%
set_engine("xgboost")
# Fit resamples
logistic_res <- fit_resamples(logistic_model, tidy_rec, tidy_k_folds)
randomForest_res <- fit_resamples(randomForest_model, tidy_rec, tidy_k_folds)
XGBoost_res <- fit_resamples(XGBoost_model, tidy_rec, tidy_k_folds)
logistic_res %>% collect_metrics()
logistic_res
logistic_res %>%
pull(.metrics)
logistic_res
logistic_res %>%
select(id, .metrics)
logistic_res %>%
select(id, .metrics) %>%
unnest(.metrics)
list(model = list(logistic_res, randomForest_res, XGBoost_res))
tibble(model = list(logistic_res, randomForest_res, XGBoost_res))
tibble(model = list(logistic_res, randomForest_res, XGBoost_res),
model_name = c("logistic", "randomForest", "XGBoost"))
model_res <- tibble(model = list(logistic_res, randomForest_res, XGBoost_res),
model_name = c("logistic", "randomForest", "XGBoost"))
logistic_res
map_collect_metrics <- function(model){
model %>%
select(id, .metrics) %>%
unnest(.metrics)
}
model_res
model_res %>%
mutate(res = map(model, map_collect_metrics))
model_res %>%
mutate(res = map(model, map_collect_metrics)) %>%
select(model_name, res) %>%
unnest(res)
model_res %>%
mutate(res = map(model, map_collect_metrics)) %>%
select(model_name, res) %>%
unnest(res) %>%
ggplot(aes(x = model_name, y = .estimate, color = model_name)) +
geom_boxplot() +
facet_wrap(~.metric)
model_res %>%
mutate(res = map(model, map_collect_metrics)) %>%
select(model_name, res) %>%
unnest(res) %>%
ggplot(aes(x = model_name, y = .estimate, color = model_name)) +
geom_boxplot() +
coord_flip() +
facet_wrap(~.metric) +
model_res %>%
mutate(res = map(model, map_collect_metrics)) %>%
select(model_name, res) %>%
unnest(res) %>%
ggplot(aes(x = model_name, y = .estimate, color = model_name)) +
geom_boxplot() +
coord_flip() +
facet_wrap(~.metric)
model_res %>%
mutate(res = map(model, map_collect_metrics)) %>%
select(model_name, res) %>%
unnest(res) %>%
ggplot(aes(x = model_name, y = .estimate, color = model_name)) +
geom_boxplot() +
coord_flip() +
facet_wrap(~.metric)
model_res %>%
mutate(res = map(model, map_collect_metrics)) %>%
select(model_name, res) %>%
unnest(res) %>%
ggplot(aes(x = model_name, y = .estimate, color = model_name)) +
geom_boxplot() +
facet_wrap(~.metric)
model_res %>%
mutate(res = map(model, map_collect_metrics)) %>%
select(model_name, res) %>%
unnest(res) %>%
filter(.metric == "accuracy") %>%
ggplot(aes(x = model_name, y = .estimate, color = model_name)) +
geom_boxplot()
model_res %>%
mutate(res = map(model, map_collect_metrics)) %>%
select(model_name, res) %>%
unnest(res) %>%
ggplot(aes(x = model_name, y = .estimate, color = model_name)) +
geom_boxplot()
model_res
model_res <- model_res %>%
mutate(res = map(model, map_collect_metrics)) %>%
select(model_name, res) %>%
unnest(res)
model_res %>%
filter(.metric == "accuracy") %>%
ggplot(aes(x = model_name, y = .estimate, color = model_name)) +
geom_boxplot()
# Use a secondary metric
model_res %>%
ggplot(aes(x = model_name, y = .estimate, color = model_name)) +
geom_boxplot()
model_res
model_res %>%
select(model_name, id, .metric, .estimate)
model_res
model_res %>%
ggplot(aes(x = model_name, y = .estimate, color = id)) +
geom_line() +
facet_wrap(~.metric)
model_res %>%
ggplot(aes(x = model_name, y = .estimate, color = id, group = interaction(model_name, id))) +
geom_line() +
facet_wrap(~.metric)
model_res %>%
ggplot(aes(x = model_name, y = .estimate, color = id, group = model_name)) +
geom_line() +
facet_wrap(~.metric)
model_res %>%
ggplot(aes(x = model_name, y = .estimate, color = id, group = id)) +
geom_line() +
facet_wrap(~.metric)
model_res %>%
ggplot(aes(x = model_name, y = .estimate, color = id, group = id)) +
geom_line() +
facet_wrap(~.metric, scales = "free_y")
model_res %>%
ggplot(aes(x = model_name, y = .estimate, color = model_name)) +
geom_boxplot()
model_res
model_res %>%
select(model_name, id, .metric, .estiamte)
model_res
model_res %>%
filter(.metric == "roc_auc")
model_res %>%
filter(.metric == "roc_auc") %>%
select(model_name, id, .estimate)
model_res %>%
filter(.metric == "roc_auc") %>%
select(model_name, id, .estimate) %>%
pivot_wider(names_from = "model_name", values_from = .estimate)
model_pos <- model_res %>%
filter(.metric == "roc_auc") %>%
select(model_name, id, .estimate) %>%
pivot_wider(names_from = "model_name", values_from = .estimate)
library(tidyposterior)
roc_model <- perf_mod(model_pos, seed = 2020)
roc_model$stan
roc_model %>% tidy()
roc_model %>% tidy() %>%
ggplot(aes(x = model, y = statistic)) +
geom_point()
contrast_models(roc_model, "logistic", "XGBoost")
contrast_models(roc_model, "logistic", "XGBoost") %>% ggplot()
roc_model %>% tidy() %>%
ggplot(aes(x = model, y = statistic))
contrast_models(roc_model, "logistic", "XGBoost") %>%
ggplot()
roc_model %>% tidy() %>%
ggplot(aes(x = model, y = statistic)) +
geom_point()
roc_model$hetero_var
roc_model$names
roc_model$rset_type
roc_model$transform
roc_model
roc_model %>% tidy()
contrast_models(roc_model, "logistic", "XGBoost")
knitr::opts_chunk$set(echo = TRUE)
library(tidymodels)
library(tidyverse)
df <- read_csv("customer_churn.csv")
df %>% summary()
df <- df %>% drop_na()
# Clean data
df <- df %>%
mutate_all(as.factor) %>%
mutate(tenure = as.numeric(tenure),
MonthlyCharges = as.numeric(MonthlyCharges),
TotalCharges = as.numeric(TotalCharges)) %>%
select(Churn, everything(), -customerID)
# Create train and test sets
set.seed(42)
tidy_split <- initial_split(df, prop = .8, strata = Churn)
train_data <- training(tidy_split)
test_data <- testing(tidy_split)
tidy_k_folds <- vfold_cv(train_data)
# Pre-process data
tidy_rec <- recipe(Churn~., data = train_data) %>%
step_normalize(all_numeric()) %>%
step_dummy(all_nominal(), -all_outcomes())
tidy_rec %>% prep()
# Create models
logistic_model <- logistic_reg() %>%
set_mode("classification") %>%
set_engine("glm")
randomForest_model <- rand_forest() %>%
set_mode("classification") %>%
set_engine("randomForest")
XGBoost_model <- boost_tree() %>%
set_mode("classification") %>%
set_engine("xgboost")
# Fit resamples
logistic_res <- fit_resamples(logistic_model, tidy_rec, tidy_k_folds)
randomForest_res <- fit_resamples(randomForest_model, tidy_rec, tidy_k_folds)
XGBoost_res <- fit_resamples(XGBoost_model, tidy_rec, tidy_k_folds)
# Extract accuracy from resample
model_res <- tibble(model = list(logistic_res, randomForest_res, XGBoost_res),
model_name = c("logistic", "randomForest", "XGBoost"))
map_collect_metrics <- function(model){
model %>%
select(id, .metrics) %>%
unnest(.metrics)
}
model_res <- model_res %>%
mutate(res = map(model, map_collect_metrics)) %>%
select(model_name, res) %>%
unnest(res)
model_res %>%
ggplot(aes(x = model_name, y = .estimate, color = model_name)) +
geom_boxplot()
model_res %>%
ggplot(aes(x = model_name, y = .estimate, color = id, group = id)) +
geom_line() +
facet_wrap(~.metric, scales = "free_y")
model_pos <- model_res %>%
filter(.metric == "roc_auc") %>%
select(model_name, id, .estimate) %>%
pivot_wider(names_from = "model_name", values_from = .estimate)
library(tidyposterior)
roc_model <- perf_mod(model_pos, seed = 2020)
roc_model %>% tidy()
roc_model %>% tidy() %>%
ggplot(aes(x = model, y = statistic)) +
geom_point()
contrast_models(roc_model, "logistic", "XGBoost")
contrast_models(roc_model, "logistic", "XGBoost") %>%
ggplot()
contrast_models(roc_model) %>%
ggplot()
model_res
model_res %>%
filter(.metric == "roc_auc")
model_res %>%
filter(.metric == "roc_auc") %>%
ggplot(aes(x = .estimate, color = model_name)) +
geom_density()
model_res %>%
filter(.metric == "roc_auc") %>%
ggplot(aes(x = .estimate, color = model_name, fill = model_name)) +
geom_density()
model_res %>%
filter(.metric == "roc_auc") %>%
ggplot(aes(x = .estimate, color = model_name, fill = model_name)) +
geom_density(alpha = .1)
setwd("E:/School/R Work/Tidy Tuesday")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels)
df <- read_csv("customer_churn.csv")
df
df %>% summary()
df <- df %>% drop_na()
df %>% summary()
◘df
df
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels)
df <- read_csv("customer_churn.csv")
df %>% summary()
df
df <- df %>% drop_na()
df
df %>%
mutate_all(as.factor)
df %>%
mutate_all(as.factor) %>%
mutate(tenure = as.numeric(tenure),
MonthlyCharges = as.numeric(MonthlyCharges),
TotalCharges = as.numeric(TotalCharges))
df %>%
mutate_all(as.factor) %>%
mutate(tenure = as.numeric(tenure),
MonthlyCharges = as.numeric(MonthlyCharges),
TotalCharges = as.numeric(TotalCharges)) %>%
summary()
df <- df %>%
mutate_all(as.factor) %>%
mutate(tenure = as.numeric(tenure),
MonthlyCharges = as.numeric(MonthlyCharges),
TotalCharges = as.numeric(TotalCharges))
df
# Pre-processing data
tidy_rec <- recipe(Churn~., data = train_data) %>%
step_rm(customerID) %>%
step_normalize(all_numeric()) %>%
step_dummy(all_nominal(), -all_outcomes())
tidy_split <- initial_split(df, prop = .8, strata = Churn)
# Create Train and test sets
set.seed(42)
tidy_split <- initial_split(df, prop = .8, strata = Churn)
train_data <- training(tidy_split)
test_data <- testing(tidy_split)
tidy_k_folds <- vfold_cv(train_data)
# Pre-processing data
tidy_rec <- recipe(Churn~., data = train_data) %>%
step_rm(customerID) %>%
step_normalize(all_numeric()) %>%
step_dummy(all_nominal(), -all_outcomes())
tidy_rec %>% prep()
baseline_model <- logistic_reg() %>%
set_mode("classification") %>%
set_engine("glm")
randomForest_model <- rand_forest() %>%
set_mode("classification") %>%
set_engine("randomForest")
XGBoost_model <- boost_tree() %>%
set_mode("classification") %>%
set_engine("xgboost")
# Fit resamples
logistic_res <- fit_resamples(baseline_model, tidy_rec, tidy_k_folds)
randomForest_res <- fit_resamples(randomForest_model, tidy_rec, tidy_k_folds)
XGBoost_res <- fit_resamples(XGBoost_model, tiidy_rec, tidy_k_folds)
XGBoost_res <- fit_resamples(XGBoost_model, tidy_rec, tidy_k_folds)
logistic_res
tibble(model = list(logistic_res, randomForest_res, XGBoost_res))
tibble(model = list(logistic_res, randomForest_res, XGBoost_res),
model_name = c("logistic", "randomForest", "XGBoost"))
model_res <- tibble(model = list(logistic_res, randomForest_res, XGBoost_res),
model_name = c("logistic", "randomForest", "XGBoost"))
model_res
logistic_res
logistic_res %>%
select(id, .metrics) %>%
unnest(.metrics)
map_collect_metrics <- function(model){
model %>%
select(id, .metrics) %>%
unnest()
}
model_res
model_res %>%
mutate(res = map(model, map_collect_metrics))
model_res %>%
mutate(res = map(model, map_collect_metrics)) %>%
select(model_name, res) %>%
unnest(res)
model_res <- model_res %>%
mutate(res = map(model, map_collect_metrics)) %>%
select(model_name, res) %>%
unnest(res)
model_res
model_res %>%
ggplot(aes(x = model_name, y = .estiamte)) +
geom_boxplot() +
facet_wrap(~.metric, scales = "free_y")
model_res %>%
ggplot(aes(x = model_name, y = .estimate)) +
geom_boxplot() +
facet_wrap(~.metric, scales = "free_y")
model_res
model_res %>%
ggplot(aes(x = model_name, y = .estimate, color = id)) +
geom_line() +
facet_wrap(~.metric, scales = "free_y")
model_res %>%
ggplot(aes(x = model_name, y = .estimate, color = id, group = id)) +
geom_line() +
facet_wrap(~.metric, scales = "free_y")
model_res
model_res %>%
ggplot(aes(x = .estimate, color = model_name, fill = model_name)) +
geom_density(alpha = .1) +
facet_wrap(~.metric, scales = "free_y")
df %>% count(Churn)
model_res
model_res %>%
group_by(model_name, .metric) %>%
summarise(mean = mean(.estimate))
model_res
model_res %>%
filter(.metric == "roc_auc")
model_res %>%
filter(.metric == "roc_auc") %>%
select(model_name, id, .estiamte)
model_res %>%
filter(.metric == "roc_auc") %>%
select(model_name, id, .estimate)
model_res %>%
filter(.metric == "roc_auc") %>%
select(model_name, id, .estimate) %>%
pivot_wider(names_from = "model_name", values_from = ".estimate")
model_pos <- model_res %>%
filter(.metric == "roc_auc") %>%
select(model_name, id, .estimate) %>%
pivot_wider(names_from = "model_name", values_from = ".estimate")
library(tidyposterior)
roc_auc_model <- perf_mod(model_pos, seed = 42)
roc_auc_model
roc_auc_model %>% tidy()
roc_auc_model %>% tidy() %>% ggplot()
roc_auc_model %>%
tidy() %>%
ggplot(aes(x = model, y = statistic)) +
geom_point()
contrast_models(roc_auc_model)
contrast_models(roc_auc_model) %>%
ggplot()
